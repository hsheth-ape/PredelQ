# Session Log: 2025-12-30-planning-001

> **Type:** Planning
> **Date:** 2025-12-30
> **Duration:** ~2 hours
> **Status:** Complete

---

## Session Goal

Bootstrap PredelQ project: create repo, establish architecture, document framework.

---

## What Happened

### 1. Repository Setup
- Created `hsheth-ape/PredelQ` repo
- Copied templates from `claude-templates-v2`
- Set up `docs/predelq/` structure

### 2. Credentials Configured
- GitHub PAT: Working
- Supabase Management API: Working
- Modal Gateway: Working
- Created Supabase project: `predelq-test` (rhvuyeiughnyapwykinu)

### 3. Framework Definition
Established the PredelQ data framework:

```
Raw Data → Metrics → Indicators (1-5) → Events → Actions
```

| Concept | Definition |
|---------|------------|
| **Metric** | Computed value (atomic, aggregate, composite) |
| **Indicator** | Scored 1-5, human-readable signal |
| **Event** | State change or threshold crossing |

### 4. Architecture Design
Designed full schema covering:
- Master data (customers, accounts, assets, OEMs, models)
- Entity identifiers (multiple IDs per entity)
- Transaction data (payments, repayment schedule, delinquency events)
- Raw data (telemetry with 90-day hot, archive forever)
- Metric/Indicator/Event system (registry + fact tables)
- Pipeline system (definitions, runs, watermarks, model registry)

Key decisions:
- Registry + fact table pattern (not one-table-per-metric)
- Watermark-based pipeline processing (not just cron)
- Pipeline performance tracking included
- 90-day hot storage for raw telemetry

---

## Decisions Made

| Decision | Choice | Rationale |
|----------|--------|-----------|
| Metric storage | Registry + fact tables | Flexible, no migrations for new metrics |
| Pipeline execution | Watermark-based | Handles gaps, processes until caught up |
| Raw data retention | 90 days hot, archive forever | Balance performance vs auditability |
| Multi-tenancy | Future-proof but single tenant MVP | Don't over-engineer |
| Identifier handling | Separate registry table | Multiple IDs per entity, no schema changes |

---

## Documents Created

| Document | Purpose |
|----------|---------|
| `SPRINT_0_INVENTORY.md` | Full architecture design with SQL schemas |
| `CURRENT.md` | Project definition and current state |
| This session log | Record of decisions |

---

## Open Questions (for next session)

1. How does raw data currently land? (API push, file drop, DB sync?)
2. What format is telemetry in? (JSON, CSV, direct DB?)
3. Are there existing tables to migrate from?
4. Metabase instance — existing or new?

---

## Next Steps

1. Human reviews `SPRINT_0_INVENTORY.md`
2. Answer data source questions
3. Create `SPRINT_0_PLAN.md` with:
   - Supabase migration scripts
   - Initial pipeline scaffolding
   - Sample data loading
4. Execute Sprint 0

---

## Promote to Project Docs

| Item | Target | Done |
|------|--------|------|
| Framework definition | CURRENT.md | ✓ |
| Architecture design | SPRINT_0_INVENTORY.md | ✓ |
| Supabase credentials | CURRENT.md | ✓ |

---

## Lessons Learned

1. GitHub secret scanning blocks commits with PATs — use references instead
2. Supabase API has occasional TLS flakiness — retry logic needed
3. Modal gateway works for Python, shell output sometimes empty
